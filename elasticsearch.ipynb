{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "s49gpkvZ7q53"
   },
   "source": [
    "# Semantic Search using ELSER v2 text expansion\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/elastic/elasticsearch-labs/blob/main/notebooks/search/03-ELSER.ipynb)\n",
    "\n",
    "\n",
    "Learn how to use the [ELSER](https://www.elastic.co/guide/en/machine-learning/current/ml-nlp-elser.html) for text expansion-powered semantic search.\n",
    "\n",
    "**`Note:`** This notebook demonstrates how to use ELSER model `.elser_model_2` model which offers an improved retrieval accuracy. \n",
    "\n",
    "If you have set up an index with ELSER model `.elser_model_1`, and would like to upgrade to ELSER v2 model - `.elser_model_2`, Please follow instructions from the notebook on [how to upgrade an index to use elser model](../model-upgrades/upgrading-index-to-use-elser.ipynb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "gEzq2Z1wBs3M"
   },
   "source": [
    "First, we need to import the modules we need.\n",
    "üîê NOTE: `getpass` enables us to securely prompt the user for credentials without echoing them to the terminal, or storing it in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "uP_GTVRi-d96"
   },
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch, helpers, exceptions\n",
    "from urllib.request import urlopen\n",
    "from getpass import getpass\n",
    "import json\n",
    "import time\n",
    "import glob"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "AMSePFiZCRqX"
   },
   "source": [
    "Now we can instantiate the Python Elasticsearch client.\n",
    "\n",
    "First we prompt the user for their password and Cloud ID.\n",
    "Then we create a `client` object that instantiates an instance of the `Elasticsearch` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h0MdAZ53CdKL",
    "outputId": "96ea6f81-f935-4d51-c4a7-af5a896180f1"
   },
   "outputs": [],
   "source": [
    "# https://www.elastic.co/search-labs/tutorials/install-elasticsearch/elastic-cloud#finding-your-cloud-id\n",
    "ELASTIC_CLOUD_ID = getpass(\"Elastic Cloud ID: \")\n",
    "\n",
    "# https://www.elastic.co/search-labs/tutorials/install-elasticsearch/elastic-cloud#creating-an-api-key\n",
    "ELASTIC_API_KEY = getpass(\"Elastic Api Key: \")\n",
    "\n",
    "# Create the client instance\n",
    "client = Elasticsearch(\n",
    "    # For local development\n",
    "    # hosts=[\"http://localhost:9200\"]\n",
    "    cloud_id=ELASTIC_CLOUD_ID,\n",
    "    api_key=ELASTIC_API_KEY,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "enHQuT57DhD1"
   },
   "source": [
    "Refer to https://www.elastic.co/guide/en/elasticsearch/client/python-api/current/connecting.html#connect-self-managed-new to learn how to connect to a self-managed deployment.\n",
    "\n",
    "Read https://www.elastic.co/guide/en/elasticsearch/client/python-api/current/connecting.html#connect-self-managed-new to learn how to connect using API keys.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download and Deploy ELSER Model\n",
    "\n",
    "In this example, we are going to download and deploy the ELSER model in our ML node. Make sure you have an ML node in order to run the ELSER model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model deleted successfully, We will proceed with creating one\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'model_id': '.elser_model_2', 'model_type': 'pytorch', 'model_package': {'packaged_model_id': 'elser_model_2', 'model_repository': 'https://ml-models.elastic.co', 'minimum_version': '11.0.0', 'size': 438123914, 'sha256': '2e0450a1c598221a919917cbb05d8672aed6c613c028008fedcd696462c81af0', 'metadata': {}, 'tags': [], 'vocabulary_file': 'elser_model_2.vocab.json'}, 'created_by': 'api_user', 'version': '12.0.0', 'create_time': 1732653094097, 'model_size_bytes': 0, 'estimated_operations': 0, 'license_level': 'platinum', 'description': 'Elastic Learned Sparse EncodeR v2', 'tags': ['elastic'], 'metadata': {}, 'input': {'field_names': ['text_field']}, 'inference_config': {'text_expansion': {'vocabulary': {'index': '.ml-inference-native-000002'}, 'tokenization': {'bert': {'do_lower_case': True, 'with_special_tokens': True, 'max_sequence_length': 512, 'truncate': 'first', 'span': -1}}}}, 'location': {'index': {'name': '.ml-inference-native-000002'}}})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# delete model if already downloaded and deployed\n",
    "try:\n",
    "    client.ml.delete_trained_model(model_id=\".elser_model_2\", force=True)\n",
    "    print(\"Model deleted successfully, We will proceed with creating one\")\n",
    "except exceptions.NotFoundError:\n",
    "    print(\"Model doesn't exist, but We will proceed with creating one\")\n",
    "\n",
    "# Creates the ELSER model configuration. Automatically downloads the model if it doesn't exist.\n",
    "client.ml.put_trained_model(\n",
    "    model_id=\".elser_model_2\", input={\"field_names\": [\"text_field\"]}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above command will download the ELSER model. This will take a few minutes to complete. Use the following command to check the status of the model download."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELSER Model is downloaded but not ready to be deployed.\n",
      "ELSER Model is downloaded but not ready to be deployed.\n",
      "ELSER Model is downloaded but not ready to be deployed.\n",
      "ELSER Model is downloaded and ready to be deployed.\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    status = client.ml.get_trained_models(\n",
    "        model_id=\".elser_model_2\", include=\"definition_status\"\n",
    "    )\n",
    "\n",
    "    if status[\"trained_model_configs\"][0][\"fully_defined\"]:\n",
    "        print(\"ELSER Model is downloaded and ready to be deployed.\")\n",
    "        break\n",
    "    else:\n",
    "        print(\"ELSER Model is downloaded but not ready to be deployed.\")\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the model is downloaded, we can deploy the model in our ML node. Use the following command to deploy the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELSER Model is currently being deployed.\n",
      "ELSER Model is currently being deployed.\n",
      "ELSER Model has been successfully deployed.\n"
     ]
    }
   ],
   "source": [
    "# Start trained model deployment if not already deployed\n",
    "client.ml.start_trained_model_deployment(\n",
    "    model_id=\".elser_model_2\", number_of_allocations=1, wait_for=\"starting\"\n",
    ")\n",
    "\n",
    "while True:\n",
    "    status = client.ml.get_trained_models_stats(\n",
    "        model_id=\".elser_model_2\",\n",
    "    )\n",
    "    if status[\"trained_model_stats\"][0][\"deployment_stats\"][\"state\"] == \"started\":\n",
    "        print(\"ELSER Model has been successfully deployed.\")\n",
    "        break\n",
    "    else:\n",
    "        print(\"ELSER Model is currently being deployed.\")\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This also will take a few minutes to complete."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "EmELvr_JK_22"
   },
   "source": [
    "# Indexing Documents with ELSER\n",
    "\n",
    "In order to use ELSER on our Elastic Cloud deployment we'll need to create an ingest pipeline that contains an inference processor that runs the ELSER model.\n",
    "Let's add that pipeline using the [`put_pipeline`](https://www.elastic.co/guide/en/elasticsearch/reference/master/put-pipeline-api.html) method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XhRng99KLQsd",
    "outputId": "00ea73b5-45a4-472b-f4bc-2c2c790ab94d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.ingest.put_pipeline(\n",
    "    id=\"elser-ingest-pipeline\",\n",
    "    description=\"Ingest pipeline for ELSER\",\n",
    "    processors=[\n",
    "        {\n",
    "            \"inference\": {\n",
    "                \"model_id\": \".elser_model_2\",\n",
    "                \"input_output\": [\n",
    "                    {\"input_field\": \"Description\", \"output_field\": \"description_embedding\"}\n",
    "                ],\n",
    "            }\n",
    "        }\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "0wCH7YHLNW3i"
   },
   "source": [
    "Let's note a few important parameters from that API call:\n",
    "\n",
    "- `inference`: A processor that performs inference using a machine learning model.\n",
    "- `model_id`: Specifies the ID of the machine learning model to be used. In this example, the model ID is set to `.elser_model_2`.\n",
    "- `input_output`: Specifies input and output fields\n",
    "- `input_field`: Field name from which the `sparse_vector` representation are created.\n",
    "- `output_field`:  Field name which contains inference results. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "TF_wxIAhD07a"
   },
   "source": [
    "## Create index\n",
    "\n",
    "To use the ELSER model at index time, we'll need to create an index mapping that supports a [`text_expansion`](https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-text-expansion-query.html) query.\n",
    "The mapping includes a field of type [`sparse_vector`](https://www.elastic.co/guide/en/elasticsearch/reference/master/sparse-vector.html)  to work with our feature vectors of interest.\n",
    "This field contains the token-weight pairs the ELSER model created based on the input text.\n",
    "\n",
    "Let's create an index named `elser-example-movies` with the mappings we need.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cvYECABJJs_2",
    "outputId": "18fb51e4-c4f6-4d1b-cb2d-bc6f8ec1aa84"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'elser-example-restaurants'})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.indices.delete(index=\"elser-example-restaurants\", ignore_unavailable=True)\n",
    "client.indices.create(\n",
    "    index=\"elser-example-restaurants\",\n",
    "    settings={\"index\": {\"default_pipeline\": \"elser-ingest-pipeline\"}},\n",
    "    mappings={\n",
    "        \"properties\": {\n",
    "            \"Description\": {\n",
    "                \"type\": \"text\",\n",
    "                \"fields\": {\"keyword\": {\"type\": \"keyword\", \"ignore_above\": 256}},\n",
    "            },\n",
    "            \"description_embedding\": {\"type\": \"sparse_vector\"},\n",
    "            # Add other fields based on your document structure if needed\n",
    "            \"docid\": { \"type\": \"keyword\" },\n",
    "            \"Title\": { \"type\": \"text\" },\n",
    "            # \"Price\": { \"type\": \"text\" },\n",
    "            # \"Place ID\": { \"type\": \"keyword\" },\n",
    "            # \"Type ID\": { \"type\": \"keyword\" },\n",
    "            # \"Type\": { \"type\": \"text\" },\n",
    "            # \"Menu\": { \"type\": \"text\"},# \"properties\": { \"item1\": { \"type\": \"text\" }, \"item2\": { \"type\": \"text\" } } },\n",
    "            # \"Address\": { \"type\": \"text\" },\n",
    "            # \"GPS Coordinates\": { \"type\": \"geo_point\" },\n",
    "            # \"Phone Number\": { \"type\": \"keyword\" },\n",
    "            # \"Rating\": { \"type\": \"float\" },\n",
    "            # \"Rating Summary\": { \"type\": \"text\" },\n",
    "            # \"Opening Hours\": { \"type\": \"text\" },\n",
    "            # \"Details\": { \"type\": \"nested\", \"properties\": { \"feature1\": { \"type\": \"text\" }, \"feature2\": { \"type\": \"text\" } } },\n",
    "            # \"Services\": { \"type\": \"nested\", \"properties\": { \"service1\": { \"type\": \"text\" }, \"service2\": { \"type\": \"text\" } } }\n",
    "        }\n",
    "    },\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "lFHgRUYVpNKP"
   },
   "source": [
    "## Insert Documents\n",
    "Let's insert our example dataset of 12 movies.\n",
    "\n",
    "If you get an error, check the model has been deployed and is available in the ML node. In newer versions of Elastic Cloud, ML node is autoscaled and the ML node may not be ready yet. Wait for a few minutes and try again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully indexed 194 documents.\n",
      "Failed to index 0 documents.\n",
      "{'count': 388, '_shards': {'total': 1, 'successful': 1, 'skipped': 0, 'failed': 0}}\n"
     ]
    }
   ],
   "source": [
    "# Helper function to load data\n",
    "def load_data(files):\n",
    "    for file in files:\n",
    "        with open(file, 'r') as f:\n",
    "            restaurant = json.load(f)\n",
    "            yield {\n",
    "                \"_index\": \"elser-example-restaurants\",\n",
    "                \"_id\": restaurant[\"docid\"],\n",
    "                \"_source\": restaurant\n",
    "            }\n",
    "\n",
    "files = glob.glob(\"data/*.json\")\n",
    "\n",
    "# Indexing data to Elasticsearch\n",
    "success, failed = 0, 0\n",
    "try:\n",
    "    for ok, action in helpers.streaming_bulk(client, load_data(files)):\n",
    "        if ok:\n",
    "            success += 1\n",
    "        else:\n",
    "            failed += 1\n",
    "except helpers.BulkIndexError as e:\n",
    "    print(f\"Bulk indexing error: {e}\")\n",
    "    for error in e.errors:\n",
    "        print(json.dumps(error, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'elser-example-restaurants': {'mappings': {'properties': {'Address': {'type': 'text', 'fields': {'keyword': {'type': 'keyword', 'ignore_above': 256}}}, 'Description': {'type': 'text', 'fields': {'keyword': {'type': 'keyword', 'ignore_above': 256}}}, 'Details': {'properties': {'accessibility': {'type': 'text', 'fields': {'keyword': {'type': 'keyword', 'ignore_above': 256}}}, 'amenities': {'type': 'text', 'fields': {'keyword': {'type': 'keyword', 'ignore_above': 256}}}, 'atmosphere': {'type': 'text', 'fields': {'keyword': {'type': 'keyword', 'ignore_above': 256}}}, 'children': {'type': 'text', 'fields': {'keyword': {'type': 'keyword', 'ignore_above': 256}}}, 'crowd': {'type': 'text', 'fields': {'keyword': {'type': 'keyword', 'ignore_above': 256}}}, 'dining_options': {'type': 'text', 'fields': {'keyword': {'type': 'keyword', 'ignore_above': 256}}}, 'from_the_business': {'type': 'text', 'fields': {'keyword': {'type': 'keyword', 'ignore_above': 256}}}, 'highlights': {'type': 'text', 'fields': {'keyword': {'type': 'keyword', 'ignore_above': 256}}}, 'offerings': {'type': 'text', 'fields': {'keyword': {'type': 'keyword', 'ignore_above': 256}}}, 'parking': {'type': 'text', 'fields': {'keyword': {'type': 'keyword', 'ignore_above': 256}}}, 'payments': {'type': 'text', 'fields': {'keyword': {'type': 'keyword', 'ignore_above': 256}}}, 'pets': {'type': 'text', 'fields': {'keyword': {'type': 'keyword', 'ignore_above': 256}}}, 'planning': {'type': 'text', 'fields': {'keyword': {'type': 'keyword', 'ignore_above': 256}}}, 'popular_for': {'type': 'text', 'fields': {'keyword': {'type': 'keyword', 'ignore_above': 256}}}, 'recycling': {'type': 'text', 'fields': {'keyword': {'type': 'keyword', 'ignore_above': 256}}}}}, 'GPS Coordinates': {'properties': {'latitude': {'type': 'float'}, 'longitude': {'type': 'float'}}}, 'Menu': {'properties': {'link': {'type': 'text', 'fields': {'keyword': {'type': 'keyword', 'ignore_above': 256}}}, 'source': {'type': 'text', 'fields': {'keyword': {'type': 'keyword', 'ignore_above': 256}}}}}, 'Opening Hours': {'properties': {'friday': {'type': 'text', 'fields': {'keyword': {'type': 'keyword', 'ignore_above': 256}}}, 'monday': {'type': 'text', 'fields': {'keyword': {'type': 'keyword', 'ignore_above': 256}}}, 'saturday': {'type': 'text', 'fields': {'keyword': {'type': 'keyword', 'ignore_above': 256}}}, 'sunday': {'type': 'text', 'fields': {'keyword': {'type': 'keyword', 'ignore_above': 256}}}, 'thursday': {'type': 'text', 'fields': {'keyword': {'type': 'keyword', 'ignore_above': 256}}}, 'tuesday': {'type': 'text', 'fields': {'keyword': {'type': 'keyword', 'ignore_above': 256}}}, 'wednesday': {'type': 'text', 'fields': {'keyword': {'type': 'keyword', 'ignore_above': 256}}}}}, 'Phone Number': {'type': 'text', 'fields': {'keyword': {'type': 'keyword', 'ignore_above': 256}}}, 'Place ID': {'type': 'text', 'fields': {'keyword': {'type': 'keyword', 'ignore_above': 256}}}, 'Price': {'type': 'text', 'fields': {'keyword': {'type': 'keyword', 'ignore_above': 256}}}, 'Rating': {'type': 'float'}, 'Rating Summary': {'properties': {'amount': {'type': 'long'}, 'stars': {'type': 'long'}}}, 'Services': {'properties': {'curbside_pickup': {'type': 'boolean'}, 'delivery': {'type': 'boolean'}, 'dine_in': {'type': 'boolean'}, 'drive_through': {'type': 'boolean'}, 'in_store_pickup': {'type': 'boolean'}, 'no_contact_delivery': {'type': 'boolean'}, 'onsite_services': {'type': 'boolean'}, 'outdoor_seating': {'type': 'boolean'}, 'takeaway': {'type': 'boolean'}, 'takeout': {'type': 'boolean'}}}, 'Title': {'type': 'text'}, 'Type': {'type': 'text', 'fields': {'keyword': {'type': 'keyword', 'ignore_above': 256}}}, 'User Reviews': {'properties': {'most_relevant': {'properties': {'contributor_id': {'type': 'text', 'fields': {'keyword': {'type': 'keyword', 'ignore_above': 256}}}, 'date': {'type': 'text', 'fields': {'keyword': {'type': 'keyword', 'ignore_above': 256}}}, 'description': {'type': 'text', 'fields': {'keyword': {'type': 'keyword', 'ignore_above': 256}}}, 'images': {'properties': {'thumbnail': {'type': 'text', 'fields': {'keyword': {'type': 'keyword', 'ignore_above': 256}}}}}, 'link': {'type': 'text', 'fields': {'keyword': {'type': 'keyword', 'ignore_above': 256}}}, 'rating': {'type': 'long'}, 'username': {'type': 'text', 'fields': {'keyword': {'type': 'keyword', 'ignore_above': 256}}}}}, 'summary': {'properties': {'snippet': {'type': 'text', 'fields': {'keyword': {'type': 'keyword', 'ignore_above': 256}}}}}}}, 'description_embedding': {'type': 'sparse_vector'}, 'docid': {'type': 'keyword'}, 'model_id': {'type': 'text', 'fields': {'keyword': {'type': 'keyword', 'ignore_above': 256}}}}}}}\n"
     ]
    }
   ],
   "source": [
    "mapping = client.indices.get_mapping(index=\"elser-example-restaurants\")\n",
    "print(mapping)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "oCj3jHHML4Tn"
   },
   "source": [
    "Inspect a new document to confirm that it now has an `plot_embedding` field that contains a list of new, additional terms.\n",
    "These terms are the **text expansion** of the field(s) you targeted for ELSER inference in `input_field` while creating the pipeline. \n",
    "ELSER essentially creates a tree of expanded terms to improve the semantic searchability of your documents.\n",
    "We'll be able to search these documents using a `text_expansion` query.\n",
    "\n",
    "But first let's start with a simple keyword search, to see how ELSER delivers semantically relevant results out of the box."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Zy5GT2xb38oz"
   },
   "source": [
    "# Searching Documents\n",
    "\n",
    "Let's test out semantic search using ELSER."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bAZRxja-5Q6X",
    "outputId": "37a26a2c-4284-4e51-c34e-9a55edf77cb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 12.648598\n",
      "Title: Knight's Steakhouse - 6\n",
      "Description: Old-school outfit serving a variety of steaks, seafood & burgers in a comfy setting with a full bar.\n",
      "\n",
      "Score: 12.648598\n",
      "Title: Knight's Steakhouse - 21\n",
      "Description: Old-school outfit serving a variety of steaks, seafood & burgers in a comfy setting with a full bar.\n",
      "\n",
      "Score: 11.546998\n",
      "Title: Gandy Dancer - 4\n",
      "Description: Elegant restaurant in a restored 1886 building serving seafood options, as well as steak & pasta.\n",
      "\n",
      "Score: 10.859073\n",
      "Title: Texas Roadhouse - 97\n",
      "Description: Lively chain steakhouse serving American fare with a Southwestern spin amid Texas-themed decor.\n",
      "\n",
      "Score: 10.459659\n",
      "Title: The Chop House Ann Arbor - 13\n",
      "Description: Chophouse decorated with elegant gas lamps offers premium steak, wine & interactive tablet menus.\n",
      "\n",
      "Score: 10.288989\n",
      "Title: Mister Spots Ann Arbor - 131\n",
      "Description: Casual joint serving Philadelphia-style hoagies, steak sandwiches & signature wings.\n",
      "\n",
      "Score: 10.247902\n",
      "Title: Texas de Brazil - Ann Arbor - 87\n",
      "Description: Upscale Brazilian eatery featuring all-you-can-eat grilled meat carved tableside & a salad bar.\n",
      "\n",
      "Score: 9.689297\n",
      "Title: The Jefferson Market - 112\n",
      "Description: Neighborhood restaurant with a diner vibe & an outdoor area serving all-day breakfast & lunch.\n",
      "\n",
      "Score: 9.272596\n",
      "Title: Ruth's Chris Steak House - 89\n",
      "Description: Outpost of upmarket steakhouse chain known for sizzling, butter-topped beef in an elegant setting\n",
      "\n",
      "Score: 8.948406\n",
      "Title: Metzger's - 14\n",
      "Description: Stalwart eatery for German & American dishes decked with antique steins & photos, plus beer garden.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h8/bfd5s_0922dbdzrpwd6d93sr0000gn/T/ipykernel_14378/747131636.py:1: ElasticsearchWarning: text_expansion is deprecated. Use sparse_vector instead.\n",
      "  response = client.search(\n"
     ]
    }
   ],
   "source": [
    "response = client.search(\n",
    "    index=\"elser-example-restaurants\",\n",
    "    size=10,\n",
    "    query={\n",
    "        \"text_expansion\": {\n",
    "            \"description_embedding\": {\n",
    "                \"model_id\": \".elser_model_2\",\n",
    "                \"model_text\": \"show me the best restaurants to get a steak at in ann arbor\",\n",
    "            }\n",
    "        }\n",
    "    },\n",
    ")\n",
    "\n",
    "\n",
    "for hit in response[\"hits\"][\"hits\"]:\n",
    "    doc_id = hit[\"_id\"]\n",
    "    score = hit[\"_score\"]\n",
    "    title = hit[\"_source\"].get(\"Title\", \"No Title\")\n",
    "    description = hit[\"_source\"].get(\"Description\", \"No Description\")\n",
    "    print(f\"Score: {score}\\nTitle: {title} - {doc_id}\\nDescription: {description}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
